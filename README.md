2025/9/6 
1. 完成了数据清洗新增加的部分，具体而言，是防止任意一个mini batch中出现任意一个神经元发放率都为0的情况，通过这种方式防止了运行的时候出现NaN的情况
2. 尝试进行了对挑出来的两个脑区进行了大规模的实验，发现出现的结果还是比较病态，势函数会出现病态的大的情况。
3. 调小了学习率进行了实验，发现实验后确实出现的结果正常了很多，不会再出现病态的势函数了。然而，此时神经元还是偏向单边的发放率
4. 换了初始化的方法后，发现单边的情况少了很多，但似乎都没怎么优化出有receptive field的情况，需要再进一步查看
5. 发现如果loss先下降后卡住，然后又开始下降，并且下降得越来越快，多半就是过拟合了。

2025/9/7
1. 通过检查实验结果，发现还是存在着不少问题。
    a. left_medulla脑区不知道为什么实验结果跑出来仍然是NaN
    b. right_ALM脑区跑出来仍旧是非常操蛋的单边的情况，也就是所有神经元的发放都是receptive field在单边而不是两边都有，为什么会出现这么诡异的情况？

从这个实验结果来看，接下来需要做的任务有
1. 首先是需要找到出现NaN的原因，然后debug。debug完成后对于所有脑区进行大规模的实验，以此确定前面说的情况是不是普遍的。
2. 从单个特例试图解决这个单边的问题。可以做的方法有：a. 画出每个神经元发放率随着时间的变化，确定到底有没有随着时间发放率变化的神经元。b. 再次观察一下边界条件是怎么设定的。

一个感悟：科研不是做题，而是一个需要工程化的大规模试错的东西，熟悉这个工程对于以后做什么事情都有用，是真的可以锻炼自己。

2025/9/9
1. 发现debug kimi是真的好用，因为已经具有了agent的能力，可以学它下一步做什么
2. 发现一个严重的错误，之前的reshape忘记order=F了，导致直接错误，才导致了超长的时间价格和随之而来的NaN错误
3. 观察数据发现可能还有一个潜在的问题，所有神经元会有一个很强的同步的发放，这个会导致结果失真(后来发现是imshow的x轴y轴弄反了，所以是自己的问题)

2025/9/12
看了一眼之前跑的结果，可以说是终于正常了；然而结果并不能给予什么有效信息。所以打算做以下几件事情：
1. 把边界条件换成reflecting, 因为实际上并不是实时决策的，而是在最后一步才决策，这个时候合适的边界条件可能就不是吸收了，而是反射。
2. 再详细阅读一下代码，观察下边界条件的含义是什么，怎么样做才是合理的
3. 再去看一下JS散度的定义是啥，阈值怎样设置才合理
4. 要去做各种数据的可视化，观察下到底有没有神经元在响应。

1. 跑了reflecting观察结果，发现靠近边界往上扬的情况消失了，这是因为此时不需要阻止粒子流失了（如果是循环边界条件的话结果可能又不一样）
4. a. 做了数据的可视化，发现之前的做法其实不太对。因为有的神经元是只在听声音的时候响应，有的只在最后舔水的时候发放。舔水阶段和等待阶段是完全不一样的两个阶段，混在一起分析是不太对的。所以照理来说，用于训练的时段还要再短点。然后我们期待训练出来的初始分布会偏向一边，不过这是否需要不同的数据源才能实现？
b. 上面是最简单的做法，如果想要更有意义的结果可以给予不同的时段不同的Phi(x)，然后可以有多个隐变量。receptive field可以跨多个变量，做些假设啥的防止空间过大过拟合。（如果要多个phi(x)，记得要一下原始数据，要不然现在时间精度太低了）
c. 看了一眼right_ALM的数据，似乎等待阶段维持响应的并不多，是不是CCA结果高全是后面的舔水阶段带来的，而不是维持记忆阶段带来的？
d. 需要自己手写一个新的边界条件才能符合现实，新的边界条件可能是sigmoid(x)啥的

2025/9/13
今天好好地重新看了NC那篇neural flow最开始的文章，尤其是关于边界条件的部分。发现：
1. 对于absorbing边界条件，absorbing operator并没有区分到底是要终止在左边还是终止在右边的情况，然而结果竟然还可以？需要去看一眼神经科学的那篇文章去知道到底有没有新加边界条件
2. 对于reflecting边界条件，是没有关于终止在哪里的条件的。

瞅了一眼猴子前额叶的那篇文章，发现确实，在训练的时候完全是无监督的，模型能够自己学会是哪一个方向，神奇。

2025/9/21
1. 拿到了新的数据。对新的数据做了可视化。发现确实是有的神经元在左边的时候发放高，有的神经元在右边的发放高，有可能可以跑出结果来。然而，这些神经元似乎都有某种时序信息，比如有的神经元只在快到结尾的时候发放等等。

2. 写了个新的python脚本，对于新的数据更换了数据预处理的方式。然后将任务提交了上去。

2025/9/22
检查了昨天跑出来的实验结果，发现：
1. 对于left Medulla脑区和right Medulla脑区，发现跑出来全是NaN。对于left Medulla脑区，甚至有跑出来是cuda memory不足的情况。
2. 对于左右ALM脑区，虽然没有出现NaN情况，然而却出现了势函数偏向一侧的情况。

因此，我需要实现：
1. 再次检查预处理的时候是否正确
2. 试图理解是否是时序信息导致了出现势函数偏向一侧的情况。
3. 需要增加画图把多个p0都画出来的功能。

检查后发现：
1. 有些trial确实出现了发放率全为0的情况，这可能导致了最终的错误。
2. 增加了画图把多个p0都画出来的功能。
3. 观察了ALM神经元的发放情况，发现确实很多神经元都携带了时间信息，这可能会导致只有一个隐变量根本学不会


2025/9/23
检查了昨天跑出来的实验结果，发现：
1. 确实修改了清洗条件之后所有脑区都不再会出现NaN的情况。
2. 实验结果并不稳定，神经元的发放率优化结果差异大。势函数也没有明显的双稳态的形状。

我的猜测：
在这个任务中，由于是固定时间，所以时间信息也是很重要的。其实有很多神经元是在表征时间信息。
因此这会迫使优化出来的势能呈现一个斜坡状，表示时间的流逝。

因此我需要：
1. 可以先试一下只把两种条件下发放率差异显著的神经元挑出来进行优化，看看实验结果是不是显著
2. 换一种概率图框架，可以支持高维信息的

2025/9/24
检查了昨天跑出来的结果，发现：
1. 即使是选择了差异最显著的神经元，大多数脑区跑出来的实验结果仍旧是一个单边的斜坡。只有left ALM跑出了一个完美的双稳态。
2. 通过去观察到底选择哪些神经元，我们会发现数据质量的差异。只有left ALM脑区中，存在大量时序信息少，同时差异大的神经元。其他脑区的数据要么是存在强烈的时间信息，要么是虽然差异大但是发放率很小。




